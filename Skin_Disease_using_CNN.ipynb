{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO076Xdkzlhssto5oSqQ+50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanialQureshi26/ML-Projects/blob/main/Skin_Disease_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNDXao6pcPD-",
        "outputId": "a9f80aee-63b5-4ba9-e559-a28f30a3c05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 739 validated image filenames belonging to 8 classes.\n",
            "Found 185 validated image filenames belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 286s 11s/step - loss: 2.1506 - accuracy: 0.1386 - val_loss: 2.0866 - val_accuracy: 0.1437 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 16s 678ms/step - loss: 2.0739 - accuracy: 0.1641 - val_loss: 2.0217 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 16s 683ms/step - loss: 2.0416 - accuracy: 0.1655 - val_loss: 1.8215 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 16s 669ms/step - loss: 2.0090 - accuracy: 0.1909 - val_loss: 1.8707 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 16s 676ms/step - loss: 1.8618 - accuracy: 0.2843 - val_loss: 1.7094 - val_accuracy: 0.3438 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 16s 682ms/step - loss: 1.8416 - accuracy: 0.2871 - val_loss: 1.5026 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 16s 672ms/step - loss: 1.7034 - accuracy: 0.3564 - val_loss: 1.4521 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 16s 679ms/step - loss: 1.5636 - accuracy: 0.4031 - val_loss: 1.3705 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 16s 680ms/step - loss: 1.3631 - accuracy: 0.4696 - val_loss: 1.2300 - val_accuracy: 0.5750 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 16s 679ms/step - loss: 1.4176 - accuracy: 0.4540 - val_loss: 1.1218 - val_accuracy: 0.5188 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 17s 701ms/step - loss: 1.2934 - accuracy: 0.5078 - val_loss: 1.0707 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 16s 671ms/step - loss: 1.2070 - accuracy: 0.5446 - val_loss: 1.1800 - val_accuracy: 0.6125 - lr: 1.0000e-04\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 16s 670ms/step - loss: 1.1747 - accuracy: 0.5686 - val_loss: 1.0895 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 16s 681ms/step - loss: 1.0513 - accuracy: 0.5983 - val_loss: 1.0637 - val_accuracy: 0.6125 - lr: 1.0000e-04\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 18s 756ms/step - loss: 0.9677 - accuracy: 0.6478 - val_loss: 0.7021 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 16s 677ms/step - loss: 1.0965 - accuracy: 0.5926 - val_loss: 0.9506 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 16s 685ms/step - loss: 1.0005 - accuracy: 0.6252 - val_loss: 0.7325 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 16s 682ms/step - loss: 0.9135 - accuracy: 0.6605 - val_loss: 0.6515 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 16s 681ms/step - loss: 0.9333 - accuracy: 0.6662 - val_loss: 0.8801 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 16s 717ms/step - loss: 0.8252 - accuracy: 0.6987 - val_loss: 0.7902 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.7908 - accuracy: 0.7459\n",
            "Test Loss: 0.7908118367195129\n",
            "Test Accuracy: 0.745945930480957\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory containing your dataset\n",
        "dataset_dir = '/content/drive/My Drive/skin disease'\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Create an ImageDataGenerator instance for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# Get the list of all image file paths and their corresponding labels\n",
        "data = []\n",
        "labels = []\n",
        "for category in os.listdir(dataset_dir):\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    for img_file in os.listdir(category_path):\n",
        "        img_path = os.path.join(category_path, img_file)\n",
        "        data.append(img_path)\n",
        "        labels.append(category)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'filename': data,\n",
        "    'class': labels\n",
        "})\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
        "\n",
        "# Create data generators\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Unfreeze some layers for fine-tuning\n",
        "for layer in base_model.layers[-4:]:  # Unfreeze the last 4 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# Create a new model on top of the pre-trained base model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(os.listdir(dataset_dir)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for learning rate adjustment and early stopping\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=20,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size,\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the image\n",
        "def preprocess_image(image_path, img_width, img_height):\n",
        "    img = load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Scale pixel values to [0, 1]\n",
        "    return img_array\n",
        "\n",
        "# Function to predict the disease from an image\n",
        "def predict_disease(image_path, model, class_indices):\n",
        "    # Preprocess the image\n",
        "    img_array = preprocess_image(image_path, img_width, img_height)\n",
        "\n",
        "    # Make a prediction\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class_idx = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Map the predicted class index to the disease name\n",
        "    class_labels = {v: k for k, v in class_indices.items()}\n",
        "    predicted_class = class_labels[predicted_class_idx]\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/drive/MyDrive/test image 3.jpg'  # Replace with the path to your image\n",
        "predicted_disease = predict_disease(image_path, model, train_generator.class_indices)\n",
        "print(\"Predicted disease:\", predicted_disease)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVpRKkbXcaMH",
        "outputId": "49beac6e-93e8-4ec6-a3da-5767e1cf20fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted disease: VI-shingles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the above mode\n",
        "\n",
        "model.save('/content/drive/MyDrive/my_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dw9lk-pfhC6",
        "outputId": "f13d149f-30cb-487c-a72b-f274398a7b30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_P_YwLUzgCL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}